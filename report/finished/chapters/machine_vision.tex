In order for the robot to navigate the factory floor in a reliable and cost-effective manner a system using lines and QR codes is proposed.
Ideally, the robot should be able to travel between points in an arbitrary grid.
A grid is made up of multiple connected colored lines.
At every point where lines intersect a QR code containing a coordinate is placed.

To facilitate this, a machine vision system using a RGB camera is proposed. The machine vision system consists of two major components.
One component is a line following algorithm which can take an image of a colored line and produce an angle between this line and the base of the robot. This angle is then used in the motor controller.
The second component is a QR code reader, this makes it possible for the robot to behave in different ways depending on the contents of the approached QR code.
These components are used in conjunction to allow the robot to travel between the points in the grid.

\section*{Line Following}
The camera is placed in a top down configuration. This makes it possible for the camera output to be regarded as a 2D surface.
The process of producing an angle from an input image of a colored line is divided into four different steps which can be summarized as follows:

\begin{enumerate}
	\item Crop out a horizontal slice
	\item Create color mask to extract line
	\item Determine center point of line using image moment
	\item Calculate angle between center point and robot base.
\end{enumerate}

% Step 1
To begin with a horizontal slice of the captured image is cropped out at a fixed vertical offset, $y_0$. This slice is visualized by the two horizontal red lines in figure \ref{fig:mv_frame}.
All remaining processing is done on this slice.
\\ \\
% Step 2
The image is then converted to HSV color space and a predetermined color mask is applied to extract only the pixels with the same color as the followed line.
This step produces a new binary image where each pixel is represented with either a 1 or a 0 depending on if the original pixel was inside the predetermined color range or not.
A visualization of this binary image is seen in the rightmost part of figure \ref{fig:mv_frame}.
This binary image is then used as the input for the next step.
\\ \\
% Step 3
To find the centroid of this binary image the \emph{moment} is calculated. The image moment is in some sense analogous to the concept of \emph{center of mass} used in physics. It is defined as
\begin{equation}
	m_{p q}=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x^{p} y^{q} I(x, y) \mathrm{d} x \mathrm{~d} y
\end{equation}
where $I(x,y)$ denotes the intensities of the image \cite{moment}.
This formula is discretized in order to be usable with an array of pixels
\begin{equation}
	M_{p q}=\sum_{x} \sum_{y} x^{p} y^{q} I(x, y).
\end{equation}
The center of the image in the horizontal direction is then given by
\begin{equation}
	\bar{x} = \frac{m_{10}}{m_{00}}.
\end{equation}
\\ \\
% Step 4
All that remains to do is then to calculate the angle between the horizontal axis and the line drawn between the point $(\bar{x}, y_0)$ and the base of the robot, denoted as $(x_r, y_r)$.
The angle $\alpha$ is then given by
\begin{equation}
	\alpha = \tan^{-1}\left(\frac{y_0 - y_r}{\bar{x} - x_r}\right).
\end{equation}
The angle output is visualized in figure \ref{fig:mv_frame}.
This process is repeated for every captured frame and will produce a continuous stream of angles which can then be used by other components of the robot.

\section*{QR Code Reader}
In order to provide the robot with additional positional information QR codes are used.
The basic QR code functionality is provided with the use of the \emph{ZBar}\cite{zbar} library.
Functionality to extract information about from which cardinal direction a QR code is being read is implemented manually.

% Does this go under MV or some other base movement section?
Each QR contains information of the form $\{x,y\}$, where $x$ and $y$ are the Cartesian coordinates of the QR code in the grid.
An internal representation of the entire grid is stored in the form of an adjacency matrix.

By taking the relative position of two adjacent QR codes together with the direction from which the robot is approaching the current QR code it is possible to calculate which way the robot must turn to reach the next QR code.

As with the line following algorithm each frame is processed and scanned for QR codes.
The contents of the QR code, the position of the QR code and the cardinal direction from which the QR code is approached is sent to be used by the other components of the robot.